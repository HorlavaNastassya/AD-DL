{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py train /u/horlavanasta/MasterProject//DataAndExperiments/Experiments/Experiments-1.5T-3T/NNs_Bayesian/ResNet18/subject_model-ResNet18_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue --n_splits 1 --split 0  --batch_size 5               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_history(model_path, num_folds):\n",
    "    from visualize.data_utils import get_data_generic\n",
    "    return os.path.exists(os.path.join(model_path, \"status.txt\"))\n",
    "    \n",
    "def check_results(model_path, MS_list, num_folds):\n",
    "    import os\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    currentDirectory = pathlib.Path(model_path)\n",
    "    currentPattern = \"fold-*\"\n",
    "    flag=True\n",
    "    for fold_dir in currentDirectory.glob(currentPattern):\n",
    "        fold = int(str(fold_dir).split(\"-\")[-1])\n",
    "\n",
    "        selection_metrics = [\"best_loss\", \"best_balanced_accuracy\", \"last_checkpoint\"]\n",
    "        cnn_classification_dir = os.path.join(model_path, 'fold-%i' % fold, 'cnn_classification')\n",
    "        \n",
    "        for selection_metric in selection_metrics:\n",
    "            modes = ['train', 'validation']\n",
    "            for ms_el in MS_list:\n",
    "                modes.append('test_' + ms_el)\n",
    "                \n",
    "            for mode in modes:\n",
    "                if not os.path.exists(os.path.join(cnn_classification_dir, selection_metric,\n",
    "                                                       '%s_image_level_metrics.tsv' % (mode))):\n",
    "                    flag=False\n",
    "                \n",
    "    return flag\n",
    "    \n",
    "def check_complete_test(model_path, num_folds, MS_list):\n",
    "    import json\n",
    "    path_params = os.path.join(model_path, \"commandline_train.json\")\n",
    "    return (check_history(model_path, num_folds) and check_results(model_path, MS_list, num_folds))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_baesian_stat(model_path, MS_list, num_folds):\n",
    "    import os\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    currentDirectory = pathlib.Path(model_path)\n",
    "    currentPattern = \"fold-*\"\n",
    "    flag=True\n",
    "    for fold_dir in currentDirectory.glob(currentPattern):\n",
    "        fold = int(str(fold_dir).split(\"-\")[-1])\n",
    "\n",
    "        selection_metrics = [\"best_loss\", \"best_balanced_accuracy\", \"last_checkpoint\"]\n",
    "        cnn_classification_dir = os.path.join(model_path, 'fold-%i' % fold, 'cnn_classification')\n",
    "        \n",
    "        for selection_metric in selection_metrics:\n",
    "            modes = ['test_' + ms_el for ms_el in MS_list]\n",
    "                \n",
    "            for mode in modes:\n",
    "                if not os.path.exists(os.path.join(cnn_classification_dir, selection_metric,\n",
    "                                                       '%s_image_level_stats.tsv' % (mode))):\n",
    "                    flag=False\n",
    "                \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_rows_and_cols(data):\n",
    "    rows_matrix = {}\n",
    "    cols_matrix = {}\n",
    "    for data_type in data.keys():\n",
    "        cols_matrix[data_type] = [selection_metric.replace(\"_\", \" \") for selection_metric in data[data_type].keys()]\n",
    "        if data_type == \"history\":\n",
    "            cols_matrix[data_type] = [\"loss\", \"balanced_accuracy\"]\n",
    "        else:\n",
    "            cols_matrix[data_type] = [selection_metric.replace(\"_\", \" \") for selection_metric in data[data_type].keys()]\n",
    "\n",
    "        if data_type == \"uncertainty_distribution\":\n",
    "            rows_matrix[data_type] = [test_MS.replace(\"_\", \" \") for test_MS in\n",
    "                                      list(data[data_type][list(data[data_type].keys())[0]].groupby(\"mode\", as_index=False, sort=False).groups.keys())]\n",
    "        else:\n",
    "            rows_matrix[data_type] = [None]\n",
    "\n",
    "    num_rows = sum([len(rows_matrix[row]) for row in rows_matrix.keys()])\n",
    "    num_cols = max([len(cols_matrix[col]) for col in cols_matrix.keys()])\n",
    "    return rows_matrix, cols_matrix, num_rows, num_cols\n",
    "\n",
    "\n",
    "def plot_history(args, data, fig, row, figshape):\n",
    "    from .plot_utils import plot_history_ax\n",
    "\n",
    "    for col, history_mode in enumerate(args.history_modes):\n",
    "        ax = plt.subplot2grid(shape=figshape, loc=(row, col), fig=fig)\n",
    "        plot_history_ax(ax, data, mode=history_mode, aggregation_type=args.aggregation_type)\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(args, data, fig, row, figshape):\n",
    "    from .plot_utils import plot_results_ax, plot_results_agg_ax\n",
    "\n",
    "    for col, selection_mode in enumerate(list(data.keys())):\n",
    "        ax = plt.subplot2grid(shape=figshape, loc=(row, col), fig=fig)\n",
    "        if args.aggregation_type is not \"all\":\n",
    "            plot_results_ax(ax, data[selection_mode], args.result_metrics)\n",
    "        else:\n",
    "            plot_results_agg_ax(ax, data[selection_mode], args.result_metrics)\n",
    "\n",
    "        ax.set_title(selection_mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_uncertainty_distribution(args, data, fig, row, figshape):\n",
    "    from .plot_utils import plot_catplot_ax, set_ylims_axes\n",
    "    axes = []\n",
    "\n",
    "    for col, selection_mode in enumerate(list(data.keys())):\n",
    "        for j, (mode, mode_group) in enumerate(data[selection_mode].groupby(\"mode\", as_index=False, sort=False)):\n",
    "            ax = plt.subplot2grid(shape=figshape, loc=(row+j, col), fig=fig)\n",
    "            plot_catplot_ax(ax,mode_group, args.uncertainty_metric, args.ba_inference_mode, args.catplot_type )\n",
    "            ax.set_title(selection_mode+\"; \"+mode)\n",
    "            axes.append(ax)\n",
    "\n",
    "    set_ylims_axes(axes)\n",
    "\n",
    "\n",
    "def plot_combined_plots(args, model_params, saved_file_path, data=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    readable_params = ['model', 'data_augmentation', 'batch_size', 'learning_rate', \"loss\", 'training MS']\n",
    "\n",
    "    rows_matrix, cols_matrix, num_rows, num_cols = get_rows_and_cols(data)\n",
    "    fig = plt.figure(figsize=((int(8 * num_cols), int(6 * num_rows))))\n",
    "\n",
    "    row = 0\n",
    "    for data_key in sorted(list(data.keys()), reverse=True):\n",
    "        eval(\"plot_%s\" % (data_key))(args, data=data[data_key], fig=fig, figshape=(num_rows, num_cols), row=row)\n",
    "        row+=len(rows_matrix[data_key])\n",
    "\n",
    "    str_suptitle = \"\\n Params: \"\n",
    "    for i, line in enumerate(readable_params):\n",
    "        str_suptitle += line + ': ' + str(model_params[line]) + \"; \"\n",
    "    str_suptitle +=\"\\n\"\n",
    "\n",
    "    plt.suptitle(str_suptitle)\n",
    "\n",
    "    # plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.1, hspace=0.1)\n",
    "    plt.subplots_adjust( left=0.05, right=0.95, top=0.95, bottom=0.05,hspace=0.3)\n",
    "\n",
    "    if saved_file_path is not None:\n",
    "        plt.savefig(saved_file_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_generic(\n",
    "        args,\n",
    "        training_MS,\n",
    "):\n",
    "    import pathlib\n",
    "    import os\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from .data_utils import get_data_generic\n",
    "\n",
    "    currentDirectory = pathlib.Path(args.model_path)\n",
    "    path_params = os.path.join(currentDirectory, \"commandline_train.json\")\n",
    "\n",
    "    with open(path_params, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    params['training MS'] = training_MS\n",
    "    args.bayesian=params[\"bayesian\"]\n",
    "    model_name = os.path.basename(os.path.normpath(currentDirectory))\n",
    "\n",
    "    folder_name = ''\n",
    "    for data_type in sorted(args.data_types):\n",
    "        if data_type==\"uncertainty_distribution\":\n",
    "            folder_name += '%s_uncertainty_%s' % (args.uncertainty_metric, args.catplot_type)\n",
    "        else:\n",
    "            folder_name += data_type\n",
    "        folder_name += \"_\"\n",
    "        \n",
    "    data=[]\n",
    "    for f in args.models: \n",
    "        data = get_data_generic(args)\n",
    "\n",
    "    for fold_key in data.keys():\n",
    "\n",
    "        if args.aggregation_type==\"separate\":\n",
    "            folder_fold_name = os.path.join(\"separate_folds\", \"fold-%s\"%fold_key)\n",
    "        else:\n",
    "            folder_fold_name = fold_key\n",
    "\n",
    "        if args.output_path:\n",
    "            saved_file_path = os.path.join(args.output_path, folder_fold_name, params[\"model\"],  folder_name)\n",
    "            os.makedirs(saved_file_path, exist_ok=True)\n",
    "            saved_file_path=os.path.join(saved_file_path, model_name + '.png')\n",
    "        else:\n",
    "            saved_file_path=None\n",
    "\n",
    "        plot_combined_plots(args, model_params=params, data=data[fold_key], saved_file_path=saved_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\"]\n",
    "\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "num_folds_arr=[5]\n",
    "isBayesian_arr=[True]\n",
    "num_folds=5\n",
    "merged_file=os.path.join(home_folder,\"DataAndExperiments/Data/DataStat\", \"merge.tsv\")\n",
    "\n",
    "for isBayesian in isBayesian_arr:\n",
    "    for MS in MS_main_list[:]:\n",
    "        print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "        model_types = [ \"ResNet18\", \"SEResNet18\", \"ResNet18Expanded\", \"SEResNet18Expanded\", \"Conv5_FC3\", \"ResNet50\", \"SEResNet50\",]\n",
    "        MS_list = MS_list_dict[MS]\n",
    "        inference_modes=[\"mode\", \"mean\"]\n",
    "        results_folder_general =os.path.join(home_folder, 'Code/ClinicaTools/AD-DL/results/', \"Experiments_%d-fold\"%num_folds, \"Experiments_Bayesian\" if isBayesian else \"Experiments\", 'Experiments-' + MS)\n",
    "        model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_%d-fold/Experiments-%s\"%(num_folds, MS), \"NNs_Bayesian\" if isBayesian else \"NNs\")\n",
    "\n",
    "        for network in model_types[:]:\n",
    "            model_dir = os.path.join(model_dir_general, network)\n",
    "            # output_dir = pathlib.Path(output_dir)\n",
    "            modelPatter = \"subject_model*\"\n",
    "            folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "            for f in folders[:]:\n",
    "                if check_complete_test(f, num_folds=num_folds, MS_list=MS_list):\n",
    "#                     pass\n",
    "                    print(f)\n",
    "                    for inference_mode in inference_modes:\n",
    "                        results_dir=os.path.join(results_folder_general, \"%s_inference\"%inference_mode)\n",
    "                        if not check_baesian_stat(f, num_folds=num_folds, MS_list=MS_list):\n",
    "                            !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py bayesian $f stat\n",
    "                        !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize $f $results_dir uncertainty_distribution results history --merged_file $merged_file --ba_inference_mode $inference_mode --catplot_type violinplot --uncertainty_metric \"total_variance\"\n",
    "#                         !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize $f $results_dir uncertainty_distribution results history --aggregation_type \"separate\" --ba_inference_mode $inference_mode --catplot_type violinplot --uncertainty_metric \"total_variance\"\n",
    "\n",
    "                else: \n",
    "                    pass\n",
    "#                     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = [\"1.5T-3T\", '1.5T', \"3T\"]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "num_folds_arr=[5]\n",
    "isBayesian_arr=[False]\n",
    "num_folds=5\n",
    "merged_file=os.path.join(home_folder,\"DataAndExperiments/Data/DataStat\", \"merge.tsv\")\n",
    "for isBayesian in isBayesian_arr:\n",
    "    for MS in MS_main_list[:]:\n",
    "        print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "        model_types = [ \"ResNet18\", \"SEResNet18\", \"ResNet18Expanded\", \"SEResNet18Expanded\", \"Conv5_FC3\", \"ResNet50\", \"SEResNet50\" ]\n",
    "        MS_list = MS_list_dict[MS]\n",
    "        inference_modes=[\"mode\", \"mean\"]\n",
    "        results_folder_general =os.path.join(home_folder, 'Code/ClinicaTools/AD-DL/results/', \"Experiments_%d-fold\"%num_folds, \"Experiments_Bayesian\" if isBayesian else \"Experiments\", 'Experiments-' + MS)\n",
    "        model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_%d-fold/Experiments-%s\"%(num_folds, MS), \"NNs_Bayesian\" if isBayesian else \"NNs\")\n",
    "\n",
    "        for network in model_types[:]:\n",
    "            model_dir = os.path.join(model_dir_general, network)\n",
    "            # output_dir = pathlib.Path(output_dir)\n",
    "            modelPatter = \"subject_model*\"\n",
    "            folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "            for f in folders[:]:\n",
    "                if check_complete_test(f, num_folds=num_folds,MS_list=MS_list):\n",
    "#                     pass\n",
    "                    print(f)\n",
    "                    \n",
    "                    results_dir=results_folder_general\n",
    "                    !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize $f $results_dir results history  --merged_file $merged_file --aggregation_type \"all\"\n",
    "\n",
    "                else: \n",
    "                    pass\n",
    "#                     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_parameters(args):\n",
    "    \"\"\"\n",
    "    Translate the names of the parameters between command line and source code.\n",
    "    \"\"\"\n",
    "    args.gpu = False\n",
    "    args.num_workers = args.nproc\n",
    "    args.optimizer = \"Adam\"\n",
    "    args.batch_size=9\n",
    "    # args.loss = \"default\"\n",
    "\n",
    "    if hasattr(args, \"caps_dir\"):\n",
    "        args.input_dir = args.caps_dir\n",
    "    if hasattr(args, \"unnormalize\"):\n",
    "        args.minmaxnormalization = not args.unnormalize\n",
    "    if hasattr(args, \"slice_direction\"):\n",
    "        args.mri_plane = args.slice_direction\n",
    "    if hasattr(args, \"network_type\"):\n",
    "        args.mode_task = args.network_type\n",
    "\n",
    "    if not hasattr(args, \"selection_threshold\"):\n",
    "        args.selection_threshold = None\n",
    "        \n",
    "    if not hasattr(args, \"verbose\"):\n",
    "        args.verbose = 0\n",
    "    if not hasattr(args, \"bayesian\"):\n",
    "        args.bayesian = False\n",
    "\n",
    "    if not hasattr(args, \"prepare_dl\"):\n",
    "        if hasattr(args, \"use_extracted_features\"):\n",
    "            args.prepare_dl = args.use_extracted_features\n",
    "        elif hasattr(args, \"use_extracted_patches\") and args.mode == \"patch\":\n",
    "            args.prepare_dl = args.use_extracted_patches\n",
    "        elif hasattr(args, \"use_extracted_slices\") and args.mode == \"slice\":\n",
    "            args.prepare_dl = args.use_extracted_slices\n",
    "        elif hasattr(args, \"use_extracted_roi\") and args.mode == \"roi\":\n",
    "            args.prepare_dl = args.use_extracted_roi\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def show_fpg(data_batch, indices=None,plane=\"sag\", num_rows=2, \n",
    "    num_cols=2, name=None, folder=\"/current_augmentations_examples/\"):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=((int(8 * num_rows), int(6 * num_cols))))\n",
    "    data_batch=data_batch.numpy()\n",
    "    print(data_batch.shape)\n",
    "    data_batch=data_batch[:num_rows*num_cols].reshape(num_rows, num_cols, data_batch.shape[1],  data_batch.shape[2],  data_batch.shape[3], \n",
    "                                  data_batch.shape[4])\n",
    "    print(data_batch.shape)\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "\n",
    "            i, j, k = indices\n",
    "            data=data_batch[row][col]\n",
    "            kwargs = dict(cmap='gray', interpolation='none')\n",
    "            slices=dict()\n",
    "            slices[\"sag\"], slices[\"cor\"], slices[\"axi\"] = np.rot90(data[0, i]), np.rot90(data[0, :, j]), np.rot90(data[0, ..., k])\n",
    "\n",
    "            axes[row][col].imshow(slices[plane],**kwargs)\n",
    "            axes[row][col].axis('off')\n",
    "            \n",
    "#     path = '../../outputs/'+folder\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "    if name is not None:\n",
    "        fig.suptitle(name)\n",
    "    plt.subplots_adjust( left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.05, hspace=0.05)\n",
    "\n",
    "#     plt.savefig(path + str(name) + '.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def show_data(model_folder, name=None, plane=\"sag\"):\n",
    "    from tools.deep_learning.models import init_model\n",
    "    from tools.deep_learning.data import (get_transforms,\n",
    "                                        load_data,\n",
    "                                        return_dataset,\n",
    "                                        generate_sampler)\n",
    "    from tools.deep_learning.iotools import return_logger\n",
    "    from argparse import Namespace\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    import torchvision.models\n",
    "    import hiddenlayer as hl\n",
    "    import torch\n",
    "\n",
    "    path_params = os.path.join(model_folder, \"commandline_train.json\")\n",
    "    with open(path_params, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    params = translate_parameters(Namespace(**params))\n",
    "    main_logger = return_logger(params.verbose, \"main process\")\n",
    "\n",
    "    \n",
    "    train_transforms, all_transforms = get_transforms(params.mode,\n",
    "                                                      minmaxnormalization=params.minmaxnormalization,\n",
    "                                                      data_augmentation=None,\n",
    "                                                      output_dir=None)\n",
    "    training_df, valid_df = load_data(\n",
    "            params.tsv_path,\n",
    "            params.diagnoses,\n",
    "            0,\n",
    "            n_splits=params.n_splits,\n",
    "            baseline=params.baseline,\n",
    "            logger=main_logger\n",
    "        )\n",
    "\n",
    "    \n",
    "    data_valid = return_dataset(params.mode, params.input_dir, valid_df, params.preprocessing,\n",
    "                                train_transformations=train_transforms, all_transformations=all_transforms,\n",
    "                                params=params)\n",
    "\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        data_valid,\n",
    "        batch_size=params.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=params.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    sample = next(iter(valid_loader))\n",
    "    \n",
    "    show_fpg(sample[\"image\"], indices=(169//2, 208//2, 179//2), name=name, plane=plane)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\" ]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "for MS in MS_main_list[:1]:\n",
    "    print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "    model_types = [ \"ResNet18\", \"SEResNet18\", \"ResNet18Expanded\", \"SEResNet18Expanded\", \"Conv5_FC3\" ]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    \n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments/Experiments-\" + MS, \"NNs\" if isBayesian else \"NNs\")\n",
    "\n",
    "    for network in model_types[:]:\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:1]:\n",
    "            print(f)\n",
    "            show_model(f)\n",
    "#             show_data(f, plane=\"sag\")\n",
    "#             show_data(f, plane=\"cor\")\n",
    "#             show_data(f, plane=\"axi\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
