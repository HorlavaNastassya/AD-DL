{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py train /u/horlavanasta/MasterProject//DataAndExperiments/Experiments/Experiments-1.5T-3T/NNs_Bayesian/ResNet18/subject_model-ResNet18_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue --n_splits 1 --split 0  --batch_size 5               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_modes=[\"loss\", \"loss\",\"balanced_accuracy\"]\n",
    "selection_metrics=[\"best_loss\", \"last_checkpoint\", \"best_balanced_accuracy\"]\n",
    "for bayesian in [True, False]:\n",
    "# bayesian=True\n",
    "    for i in range(len(selection_metrics)):\n",
    "        history_mode=history_modes[i]\n",
    "        selection_metric=selection_metrics[i]\n",
    "        !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/plot_combined.py --history_mode $history_mode --selection_metric $selection_metric --bayesian $bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_history(model_path, num_folds):\n",
    "    from visualize.data_utils import get_data_generic\n",
    "    return os.path.exists(os.path.join(model_path, \"status.txt\"))\n",
    "    \n",
    "def check_results(model_path, MS_list, num_folds):\n",
    "    import os\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    currentDirectory = pathlib.Path(model_path)\n",
    "    currentPattern = \"fold-*\"\n",
    "    flag=True\n",
    "    for fold_dir in currentDirectory.glob(currentPattern):\n",
    "        fold = int(str(fold_dir).split(\"-\")[-1])\n",
    "\n",
    "        selection_metrics = [\"best_loss\", \"best_balanced_accuracy\", \"last_checkpoint\"]\n",
    "        cnn_classification_dir = os.path.join(model_path, 'fold-%i' % fold, 'cnn_classification')\n",
    "        \n",
    "        for selection_metric in selection_metrics:\n",
    "            modes = ['train', 'validation']\n",
    "            for ms_el in MS_list:\n",
    "                modes.append('test_' + ms_el)\n",
    "                \n",
    "            for mode in modes:\n",
    "                if not os.path.exists(os.path.join(cnn_classification_dir, selection_metric,\n",
    "                                                       '%s_image_level_metrics.tsv' % (mode))):\n",
    "                    flag=False\n",
    "                \n",
    "    return flag\n",
    "    \n",
    "def check_complete_test(model_path, num_folds, MS_list):\n",
    "    import json\n",
    "    path_params = os.path.join(model_path, \"commandline_train.json\")\n",
    "    return (check_history(model_path, num_folds) and check_results(model_path, MS_list, num_folds))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_baesian_stat(model_path, MS_list, num_folds):\n",
    "    import os\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    currentDirectory = pathlib.Path(model_path)\n",
    "    currentPattern = \"fold-*\"\n",
    "    flag=True\n",
    "    for fold_dir in currentDirectory.glob(currentPattern):\n",
    "        fold = int(str(fold_dir).split(\"-\")[-1])\n",
    "\n",
    "        selection_metrics = [\"best_loss\", \"best_balanced_accuracy\", \"last_checkpoint\"]\n",
    "        cnn_classification_dir = os.path.join(model_path, 'fold-%i' % fold, 'cnn_classification')\n",
    "        \n",
    "        for selection_metric in selection_metrics:\n",
    "            modes = ['test_' + ms_el for ms_el in MS_list]\n",
    "                \n",
    "            for mode in modes:\n",
    "                if not os.path.exists(os.path.join(cnn_classification_dir, selection_metric,\n",
    "                                                       '%s_image_level_stats.tsv' % (mode))):\n",
    "                    flag=False\n",
    "                \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS 1.5T \n",
      " ____________________________________________________________________________________________\n",
      "MS 1.5T-3T \n",
      " ____________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "MS_main_list = ['1.5T', \"1.5T-3T\"]\n",
    "num_folds=5\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'    \n",
    "merged_file=os.path.join(home_folder,\"DataAndExperiments/Data/DataStat\", \"merge.tsv\")\n",
    "# inference_modes=[\"mode\", \"mean\"]\n",
    "inference_modes=[\"mean\"]\n",
    "\n",
    "\n",
    "\n",
    "preprocessing=\"linear\"\n",
    "history_modes=[\"loss\", \"loss\",\"balanced_accuracy\"]\n",
    "selection_metrics=[\"best_loss\", \"last_checkpoint\", \"best_balanced_accuracy\"]\n",
    "isBayesian=True\n",
    "for isBayesian in [True]:\n",
    "    for MS in MS_main_list[:]:\n",
    "        print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "        model_types = [ \"ResNet18\", \"SEResNet18\", \"ResNet18Expanded\", \"SEResNet18Expanded\", \"Conv5_FC3\", \"ResNet50\", \"SEResNet50\"]\n",
    "        MS_list = MS_list_dict[MS]\n",
    "\n",
    "        results_folder_general =os.path.join(home_folder, 'Code/ClinicaTools/AD-DL/results/', \"Experiments_%d-fold\"%num_folds,\n",
    "                                             \"Experiments_Bayesian\" if isBayesian else \"Experiments\", 'Experiments-' + MS)\n",
    "\n",
    "        model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_%d-fold/Experiments-%s\"%(num_folds, MS),\n",
    "                                         \"NNs_Bayesian\" if isBayesian else \"NNs\")\n",
    "    #         print(args.preprocessing)\n",
    "\n",
    "        for network in model_types[:]:\n",
    "\n",
    "            model_dir = os.path.join(model_dir_general, network)\n",
    "            modelPatter = \"subject_model*\"\n",
    "            folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "            models_list=[]\n",
    "\n",
    "            for f in folders[:]:\n",
    "                for i in range(len(selection_metrics)):\n",
    "#                     history_mode=history_modes[i]\n",
    "                    selection_metric=selection_metrics[i]\n",
    "                    results_dir=os.path.join(results_folder_general, \"preprocessing-%s\"%preprocessing, \"%s_selection\"%selection_metric)\n",
    "    #                 results_dir=os.path.join(results_folder_general, \"preprocessing-%s\"%preprocessing)\n",
    "\n",
    "    #                 print(results_dir)\n",
    "                    if check_complete_test(f, num_folds=num_folds, MS_list=MS_list) and \"_preprocessing-%s_\"%preprocessing in str(f):\n",
    "                        if isBayesian:\n",
    "                            if not check_baesian_stat(f, num_folds=num_folds, MS_list=MS_list):\n",
    "                                prefixes = [\"test_\" + magnet_strength for magnet_strength in MS_list]\n",
    "                                !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py bayesian $f stat\n",
    "                            for inference_mode in inference_modes:\n",
    "                                results_dir=os.path.join(results_dir, \"%s_inference\"%inference_mode)\n",
    "#                                 !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize --model_path $f --output_path $results_dir --data_types results history --merged_file $merged_file --ba_inference_mode $inference_mode --history_modes \"loss\" \"balanced_accuracy\" --selection_metrics $selection_metric --uncertainty_metric \"total_variance\"\n",
    "                                !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize --model_path $f --output_path $results_dir --data_types uncertainty_distribution --merged_file $merged_file --ba_inference_mode $inference_mode --selection_metrics $selection_metric --uncertainty_metric \"total_variance\" --aggregation_type \"separate\"\n",
    "\n",
    "    #                             !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize --model_path $f --output_path $results_dir --data_types results history uncertainty_distribution --merged_file $merged_file --ba_inference_mode $inference_mode\n",
    "                        else:\n",
    "                                !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize --model_path $f --output_path $results_dir --data_types results history --merged_file $merged_file --history_modes \"loss\" \"balanced_accuracy\" --selection_metrics $selection_metric\n",
    "    #                             !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize --model_path $f --output_path $results_dir --data_types results history --merged_file $merged_file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_parameters(args):\n",
    "    \"\"\"\n",
    "    Translate the names of the parameters between command line and source code.\n",
    "    \"\"\"\n",
    "    args.gpu = False\n",
    "    args.num_workers = args.nproc\n",
    "    args.optimizer = \"Adam\"\n",
    "    args.batch_size=9\n",
    "    # args.loss = \"default\"\n",
    "\n",
    "    if hasattr(args, \"caps_dir\"):\n",
    "        args.input_dir = args.caps_dir\n",
    "    if hasattr(args, \"unnormalize\"):\n",
    "        args.minmaxnormalization = not args.unnormalize\n",
    "    if hasattr(args, \"slice_direction\"):\n",
    "        args.mri_plane = args.slice_direction\n",
    "    if hasattr(args, \"network_type\"):\n",
    "        args.mode_task = args.network_type\n",
    "\n",
    "    if not hasattr(args, \"selection_threshold\"):\n",
    "        args.selection_threshold = None\n",
    "        \n",
    "    if not hasattr(args, \"verbose\"):\n",
    "        args.verbose = 0\n",
    "    if not hasattr(args, \"bayesian\"):\n",
    "        args.bayesian = False\n",
    "\n",
    "    if not hasattr(args, \"prepare_dl\"):\n",
    "        if hasattr(args, \"use_extracted_features\"):\n",
    "            args.prepare_dl = args.use_extracted_features\n",
    "        elif hasattr(args, \"use_extracted_patches\") and args.mode == \"patch\":\n",
    "            args.prepare_dl = args.use_extracted_patches\n",
    "        elif hasattr(args, \"use_extracted_slices\") and args.mode == \"slice\":\n",
    "            args.prepare_dl = args.use_extracted_slices\n",
    "        elif hasattr(args, \"use_extracted_roi\") and args.mode == \"roi\":\n",
    "            args.prepare_dl = args.use_extracted_roi\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def show_fpg(data_batch, indices=None,plane=\"sag\", num_rows=2, \n",
    "    num_cols=2, name=None, folder=\"/current_augmentations_examples/\"):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=((int(8 * num_rows), int(6 * num_cols))))\n",
    "    data_batch=data_batch.numpy()\n",
    "    print(data_batch.shape)\n",
    "    data_batch=data_batch[:num_rows*num_cols].reshape(num_rows, num_cols, data_batch.shape[1],  data_batch.shape[2],  data_batch.shape[3], \n",
    "                                  data_batch.shape[4])\n",
    "    print(data_batch.shape)\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "\n",
    "            i, j, k = indices\n",
    "            data=data_batch[row][col]\n",
    "            kwargs = dict(cmap='gray', interpolation='none')\n",
    "            slices=dict()\n",
    "            slices[\"sag\"], slices[\"cor\"], slices[\"axi\"] = np.rot90(data[0, i]), np.rot90(data[0, :, j]), np.rot90(data[0, ..., k])\n",
    "\n",
    "            axes[row][col].imshow(slices[plane],**kwargs)\n",
    "            axes[row][col].axis('off')\n",
    "            \n",
    "#     path = '../../outputs/'+folder\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "    if name is not None:\n",
    "        fig.suptitle(name)\n",
    "    plt.subplots_adjust( left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.05, hspace=0.05)\n",
    "\n",
    "#     plt.savefig(path + str(name) + '.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def show_data(model_folder, name=None, plane=\"sag\"):\n",
    "    from tools.deep_learning.models import init_model\n",
    "    from tools.deep_learning.data import (get_transforms,\n",
    "                                        load_data,\n",
    "                                        return_dataset,\n",
    "                                        generate_sampler)\n",
    "    from tools.deep_learning.iotools import return_logger\n",
    "    from argparse import Namespace\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    import torchvision.models\n",
    "    import hiddenlayer as hl\n",
    "    import torch\n",
    "\n",
    "    path_params = os.path.join(model_folder, \"commandline_train.json\")\n",
    "    with open(path_params, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    params = translate_parameters(Namespace(**params))\n",
    "    main_logger = return_logger(params.verbose, \"main process\")\n",
    "\n",
    "    \n",
    "    train_transforms, all_transforms = get_transforms(params.mode,\n",
    "                                                      minmaxnormalization=params.minmaxnormalization,\n",
    "                                                      data_augmentation=None,\n",
    "                                                      output_dir=None)\n",
    "    training_df, valid_df = load_data(\n",
    "            params.tsv_path,\n",
    "            params.diagnoses,\n",
    "            0,\n",
    "            n_splits=params.n_splits,\n",
    "            baseline=params.baseline,\n",
    "            logger=main_logger\n",
    "        )\n",
    "\n",
    "    \n",
    "    data_valid = return_dataset(params.mode, params.input_dir, valid_df, params.preprocessing,\n",
    "                                train_transformations=train_transforms, all_transformations=all_transforms,\n",
    "                                params=params)\n",
    "\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        data_valid,\n",
    "        batch_size=params.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=params.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    sample = next(iter(valid_loader))\n",
    "    \n",
    "    show_fpg(sample[\"image\"], indices=(169//2, 208//2, 179//2), name=name, plane=plane)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\" ]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "for MS in MS_main_list[:1]:\n",
    "    print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "    model_types = [ \"ResNet18\", \"SEResNet18\", \"ResNet18Expanded\", \"SEResNet18Expanded\", \"Conv5_FC3\" ]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    \n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments/Experiments-\" + MS, \"NNs\" if isBayesian else \"NNs\")\n",
    "\n",
    "    for network in model_types[:]:\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:1]:\n",
    "            print(f)\n",
    "            show_model(f)\n",
    "#             show_data(f, plane=\"sag\")\n",
    "#             show_data(f, plane=\"cor\")\n",
    "#             show_data(f, plane=\"axi\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
