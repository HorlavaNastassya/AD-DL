{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py train /u/horlavanasta/MasterProject//DataAndExperiments/Experiments/Experiments-1.5T-3T/NNs_Bayesian/ResNet18/subject_model-ResNet18_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue --n_splits 1 --split 0  --batch_size 5               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py train /u/horlavanasta/MasterProject//DataAndExperiments/Experiments_3-fold/Experiments-1.5T/NNs_Bayesian/SEResNet18Expanded/subject_model-SEResNet18Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210528_130201/ --resume True --n_splits 3 --nproc 2 --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_history(model_path, epochs, num_folds):\n",
    "    from visualize.data_utils import get_data_generic\n",
    "    from argparse import Namespace\n",
    "    \n",
    "    finished_folds=0\n",
    "\n",
    "    if not os.path.exists(os.path.join(model_path, \"status.txt\")):\n",
    "        args = Namespace()\n",
    "        args.model_path=model_path\n",
    "        args.data_types=[\"history\"]\n",
    "        args.average_fold=False\n",
    "        data = get_data_generic(args, reshape_dict=False)\n",
    "        finished_folds=0\n",
    "        for fold, fold_data in data[\"history\"].items():\n",
    "            if len(fold_data[[\"epoch\"]])==epochs:\n",
    "                finished_folds+=1\n",
    "        if finished_folds==num_folds:\n",
    "            print(\"Finished:\", model_path)\n",
    "            with open(os.path.join(model_path, \"status.txt\"), \"w\") as f:\n",
    "                f.write(\"Status: job was finished for all folds\")\n",
    "        return finished_folds==num_folds\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def check_results(model_path, MS_list, num_folds):\n",
    "    import os\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    currentDirectory = pathlib.Path(model_path)\n",
    "    currentPattern = \"fold-*\"\n",
    "    flag=True\n",
    "    for fold_dir in currentDirectory.glob(currentPattern):\n",
    "        fold = int(str(fold_dir).split(\"-\")[-1])\n",
    "\n",
    "        selection_metrics = [\"best_loss\", \"best_balanced_accuracy\", \"last_checkpoint\"]\n",
    "        cnn_classification_dir = os.path.join(model_path, 'fold-%i' % fold, 'cnn_classification')\n",
    "        \n",
    "        for selection_metric in selection_metrics:\n",
    "            modes = ['train', 'validation']\n",
    "            for ms_el in MS_list:\n",
    "                modes.append('test_' + ms_el)\n",
    "                \n",
    "            for mode in modes:\n",
    "                if not os.path.exists(os.path.join(cnn_classification_dir, selection_metric,\n",
    "                                                       '%s_image_level_metrics.tsv' % (mode))):\n",
    "                    flag=False\n",
    "                \n",
    "    return flag\n",
    "    \n",
    "def check_complete_test(model_path, num_folds, MS_list):\n",
    "    import json\n",
    "    path_params = os.path.join(model_path, \"commandline_train.json\")\n",
    "    with open(path_params, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    epochs=params[\"epochs\"]\n",
    "#     check_history(model_path, epochs, num_folds)\n",
    "    return (check_history(model_path, epochs, num_folds) and not check_results(model_path, MS_list, num_folds))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\"]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "NBR_BAYESIAN_ITER=10\n",
    "\n",
    "num_folds=5\n",
    "for MS in MS_main_list[:]:\n",
    "#     print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "    model_types = [ \"ResNet18\",  \"ResNet18Expanded\", \"Conv5_FC3\",  \"SEResNet50\",\"SEResNet50Expanded\" ]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    inference_modes=[\"mode\", \"mean\"]\n",
    "    results_folder_general =os.path.join(home_folder, 'Code/ClinicaTools/AD-DL/results/', \"Experiments_%d-fold\"%num_folds, \"Experiments_Bayesian\" if isBayesian else \"Experiments\", 'Experiments-' + MS)\n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_%d-fold/Experiments-%s\"%(num_folds, MS), \"NNs_Bayesian\" if isBayesian else \"NNs\")\n",
    "    CAPS_DIR=\"$HOME/MasterProject/DataAndExperiments/Data/CAPS\"\n",
    "    if isBayesian:\n",
    "        NN_FOLDER=\"NNs_Bayesian\"\n",
    "    else:\n",
    "        NN_FOLDER=\"NNs\"\n",
    "\n",
    "\n",
    "    TSV_PATH=\"/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-%s/labels/test\"%MS\n",
    "    for network in model_types[:]:\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        OUTPUT_DIR=\"/u/horlavanasta/MasterProject//DataAndExperiments/Experiments_5-fold/Experiments-%s/%s/%s/\"%(MS, NN_FOLDER, network)\n",
    "        POSTFIX=\"test_%s\"%MS\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:]:\n",
    "            if check_complete_test(f, num_folds=num_folds,MS_list=MS_list):\n",
    "                print(\"srun python3 /u/horlavanasta/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py classify %s %s %s %s --bayesian %s --nbr_bayesian_iter %d --selection_metrics balanced_accuracy loss last_checkpoint\"%(CAPS_DIR, TSV_PATH, f, POSTFIX, isBayesian, NBR_BAYESIAN_ITER))\n",
    "                if MS == \"1.5T\":\n",
    "                    TEST_MS=\"3T\"\n",
    "                    TEST_POSTFIX=\"test_%s\"%TEST_MS\n",
    "                    TEST_TSV_PATH=\"/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-%s/labels/\"%TEST_MS\n",
    "                    print(\"srun python3 /u/horlavanasta/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py classify %s %s %s %s --bayesian %s --nbr_bayesian_iter %d --selection_metrics balanced_accuracy loss last_checkpoint\"%(CAPS_DIR, TEST_TSV_PATH, f, TEST_POSTFIX, isBayesian, NBR_BAYESIAN_ITER))\n",
    "\n",
    "\n",
    "                elif MS == \"3T\":\n",
    "                    TEST_MS=\"1.5T\"\n",
    "                    TEST_POSTFIX=\"test_%s\"%TEST_MS\n",
    "                    TEST_TSV_PATH=\"/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-%s/labels/\"%TEST_MS\n",
    "                    print(\"srun python3 /u/horlavanasta/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py classify %s %s %s %s --bayesian %s --nbr_bayesian_iter %d --selection_metrics balanced_accuracy loss last_checkpoint\"%(CAPS_DIR, TEST_TSV_PATH, f, TEST_POSTFIX, isBayesian, NBR_BAYESIAN_ITER))\n",
    "\n",
    "#                     for inference_mode in inference_modes:\n",
    "#                         results_dir=os.path.join(results_folder_general,network, \"%s_inference\"%inference_mode)\n",
    "#                         !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py bayesian $f stat\n",
    "#                         !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize $f $results_dir uncertainty_distribution results history --get_test_from_bayesian True --ba_inference_mode $inference_mode --catplot_type violinplot --uncertainty_metric \"total_variance\"\n",
    "#                         !python ~/MasterProject/Code/ClinicaTools/AD-DL/clinicaaddl/clinicaaddl/main.py visualize $f $results_dir uncertainty_distribution results history --average_fold False --get_test_from_bayesian True --ba_inference_mode $inference_mode --catplot_type violinplot --uncertainty_metric \"total_variance\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_parameters(args):\n",
    "    \"\"\"\n",
    "    Translate the names of the parameters between command line and source code.\n",
    "    \"\"\"\n",
    "#     args.gpu = True\n",
    "    args.optimizer = \"Adam\"\n",
    "    args.batch_size=8\n",
    "    args.nproc=8\n",
    "    # args.loss = \"default\"\n",
    "\n",
    "    if hasattr(args, \"caps_dir\"):\n",
    "        args.input_dir = args.caps_dir\n",
    "    if hasattr(args, \"unnormalize\"):\n",
    "        args.minmaxnormalization = not args.unnormalize\n",
    "    if hasattr(args, \"slice_direction\"):\n",
    "        args.mri_plane = args.slice_direction\n",
    "    if hasattr(args, \"network_type\"):\n",
    "        args.mode_task = args.network_type\n",
    "\n",
    "    if not hasattr(args, \"selection_threshold\"):\n",
    "        args.selection_threshold = None\n",
    "        \n",
    "    if not hasattr(args, \"verbose\"):\n",
    "        args.verbose = 0\n",
    "    if not hasattr(args, \"bayesian\"):\n",
    "        args.bayesian = False\n",
    "\n",
    "    if not hasattr(args, \"prepare_dl\"):\n",
    "        if hasattr(args, \"use_extracted_features\"):\n",
    "            args.prepare_dl = args.use_extracted_features\n",
    "        elif hasattr(args, \"use_extracted_patches\") and args.mode == \"patch\":\n",
    "            args.prepare_dl = args.use_extracted_patches\n",
    "        elif hasattr(args, \"use_extracted_slices\") and args.mode == \"slice\":\n",
    "            args.prepare_dl = args.use_extracted_slices\n",
    "        elif hasattr(args, \"use_extracted_roi\") and args.mode == \"roi\":\n",
    "            args.prepare_dl = args.use_extracted_roi\n",
    "\n",
    "    return args\n",
    "\n",
    "def rename_model(model_path, new_name=\"SEResNet50\"):\n",
    "    \n",
    "    from tools.deep_learning.models import init_model\n",
    "    from tools.deep_learning.iotools import read_json, commandline_to_json\n",
    "    \n",
    "    from argparse import Namespace\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    import torchvision.models\n",
    "    import hiddenlayer as hl\n",
    "    import torch\n",
    "\n",
    "    args=Namespace()\n",
    "#     args.model_path=model_path\n",
    "    \n",
    "    args = read_json(args, json_path=os.path.join(model_path, 'commandline.json'))\n",
    "#     args.model=new_name\n",
    "    args.output_dir=model_path\n",
    "    args.nproc=2\n",
    "    args.batch_size=2\n",
    "\n",
    "\n",
    "    commandline_to_json(args, filename=\"commandline.json\")\n",
    "    \n",
    "    if os.path.exists(os.path.join(args.output_dir, 'commandline_train.json')):\n",
    "        args=Namespace()\n",
    "        args = read_json(args, json_path=os.path.join(model_path, 'commandline_train.json'))\n",
    "#         args.model=new_name\n",
    "        args.output_dir=model_path\n",
    "        args.batch_size=8\n",
    "        args.nproc=8\n",
    "\n",
    "        commandline_to_json(args, filename=\"commandline_train.json\")\n",
    "    \n",
    "#     new_model_folder=model_path.replace(old_name, new_name)\n",
    "#     os.makedirs(new_model_folder, exist_ok=True)\n",
    "#     os.rename(model_path,new_model_folder)\n",
    "#     os.remove(model_path)\n",
    "#     print(new_model_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS 1.5T \n",
      " ____________________________________________________________________________________________\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132309\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132306\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132303\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132312\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132328\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132334\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132331\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132337\n",
      "MS 3T \n",
      " ____________________________________________________________________________________________\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132407\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132414\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132404\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132410\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132435\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132438\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132432\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132428\n",
      "MS 1.5T-3T \n",
      " ____________________________________________________________________________________________\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132202\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132211\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132208\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132205\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50/subject_model-SEResNet50_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse_20210604_132236\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue_20210604_132233\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmTrue\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmFalse_20210604_132230\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-default_augmFalse\n",
      "/u/horlavanasta/MasterProject/DataAndExperiments/Experiments_5-fold/Experiments-1.5T-3T/NNs_Bayesian/SEResNet50Expanded/subject_model-SEResNet50Expanded_preprocessing-linear_task-AD_CN_norm-1_loss-WeightedCrossEntropy_augmTrue_20210604_132227\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\"]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "for MS in MS_main_list[:]:\n",
    "    print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "#     model_types = [\"SEResNet18\", \"SEResNet18Expanded\"]\n",
    "    new_model_types = [\"SEResNet50\", \"SEResNet50Expanded\"]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    \n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_5-fold/Experiments-\" + MS, \"NNs_Bayesian\" if isBayesian else \"NNs\")\n",
    "\n",
    "    for i, network in enumerate(new_model_types[:]):\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:]:\n",
    "            print(str(f))\n",
    "            rename_model(str(f), new_name=new_model_types[i])\n",
    "#             show_data(f, plane=\"sag\")\n",
    "#             show_data(f, plane=\"cor\")\n",
    "#             show_data(f, plane=\"axi\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_parameters(args):\n",
    "    \"\"\"\n",
    "    Translate the names of the parameters between command line and source code.\n",
    "    \"\"\"\n",
    "    args.gpu = True\n",
    "    args.optimizer = \"Adam\"\n",
    "    args.nproc = 2\n",
    "    args.batch_size=8\n",
    "    \n",
    "    # args.loss = \"default\"\n",
    "\n",
    "    if hasattr(args, \"caps_dir\"):\n",
    "        args.input_dir = args.caps_dir\n",
    "    if hasattr(args, \"unnormalize\"):\n",
    "        args.minmaxnormalization = not args.unnormalize\n",
    "    if hasattr(args, \"slice_direction\"):\n",
    "        args.mri_plane = args.slice_direction\n",
    "    if hasattr(args, \"network_type\"):\n",
    "        args.mode_task = args.network_type\n",
    "\n",
    "    if not hasattr(args, \"selection_threshold\"):\n",
    "        args.selection_threshold = None\n",
    "        \n",
    "    if not hasattr(args, \"verbose\"):\n",
    "        args.verbose = 0\n",
    "    if not hasattr(args, \"bayesian\"):\n",
    "        args.bayesian = False\n",
    "\n",
    "    if not hasattr(args, \"prepare_dl\"):\n",
    "        if hasattr(args, \"use_extracted_features\"):\n",
    "            args.prepare_dl = args.use_extracted_features\n",
    "        elif hasattr(args, \"use_extracted_patches\") and args.mode == \"patch\":\n",
    "            args.prepare_dl = args.use_extracted_patches\n",
    "        elif hasattr(args, \"use_extracted_slices\") and args.mode == \"slice\":\n",
    "            args.prepare_dl = args.use_extracted_slices\n",
    "        elif hasattr(args, \"use_extracted_roi\") and args.mode == \"roi\":\n",
    "            args.prepare_dl = args.use_extracted_roi\n",
    "\n",
    "    return args\n",
    "\n",
    "def show_model(model_folder):\n",
    "    \n",
    "    from tools.deep_learning.models import init_model\n",
    "    from tools.deep_learning.data import (get_transforms,\n",
    "                                        load_data,\n",
    "                                        return_dataset,\n",
    "                                        generate_sampler)\n",
    "    from tools.deep_learning.iotools import return_logger\n",
    "    from argparse import Namespace\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    import torchvision.models\n",
    "    import hiddenlayer as hl\n",
    "    import torch\n",
    "    from torch.autograd import Variable\n",
    "\n",
    "    path_params = os.path.join(model_folder, \"commandline.json\")\n",
    "    with open(path_params, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    params = translate_parameters(Namespace(**params))\n",
    "    \n",
    "    main_logger = return_logger(params.verbose, \"main process\")\n",
    "    model = init_model(params, initial_shape=None)\n",
    "    \n",
    "#     model.to(torch.device('cpu'))\n",
    "\n",
    "#     import torch.onnx\n",
    "#     dummy_input = Variable(torch.randn(1,1, 128, 128, 128))\n",
    "#     torch.onnx.export(model, dummy_input, \"/u/horlavanasta/MasterProject/model_%s.onnx\"%params.model)\n",
    "    from torchsummary import summary\n",
    "    print(model)\n",
    "    \n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\" ]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "for MS in MS_main_list[:1]:\n",
    "    print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "    model_types = [\"ResNet18\"]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    \n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments_5-fold/Experiments-\" + MS, \"NNs\" if isBayesian else \"NNs\")\n",
    "\n",
    "    for network in model_types[:]:\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:1]:\n",
    "            print(f)\n",
    "            show_model(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folders = []\n",
    "MS_main_list = ['1.5T', \"3T\",\"1.5T-3T\" ]\n",
    "MS_list_dict = {'1.5T':['1.5T', '3T'], \"3T\": ['3T', '1.5T'], \"1.5T-3T\": [\"1.5T-3T\"]}\n",
    "home_folder='/u/horlavanasta/MasterProject/'\n",
    "\n",
    "isBayesian=True\n",
    "for MS in MS_main_list[:1]:\n",
    "    print(\"MS %s \\n ____________________________________________________________________________________________\"%MS)\n",
    "    model_types = [\"ResNet18\" ]\n",
    "    MS_list = MS_list_dict[MS]\n",
    "    \n",
    "    model_dir_general = os.path.join(home_folder,\"DataAndExperiments/Experiments/Experiments-\" + MS, \"NNs\" if isBayesian else \"NNs\")\n",
    "\n",
    "    for network in model_types[:]:\n",
    "        model_dir = os.path.join(model_dir_general, network)\n",
    "        # output_dir = pathlib.Path(output_dir)\n",
    "        modelPatter = \"subject_model*\"\n",
    "        folders = [f for f in pathlib.Path(model_dir).glob(modelPatter)]\n",
    "\n",
    "        for f in folders[:1]:\n",
    "            print(f)\n",
    "            show_model(f)\n",
    "#             show_data(f, plane=\"sag\")\n",
    "#             show_data(f, plane=\"cor\")\n",
    "#             show_data(f, plane=\"axi\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
